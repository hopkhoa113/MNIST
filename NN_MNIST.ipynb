{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X425GwzoSmC2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "dQEASbUnS9oN",
    "outputId": "52d8f883-9540-4d4f-e5d4-54dbacebb202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h7XozSMbS-pQ"
   },
   "outputs": [],
   "source": [
    "def pre_process(path):\n",
    "    label=[]\n",
    "    data=[]\n",
    "    with open(path, 'r') as csvFile:\n",
    "        reader = csv.reader(csvFile)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            label.append(row[0])\n",
    "            img=np.array(row[1:],dtype='float')/255.0\n",
    "            img.resize(28,28)\n",
    "            data.append(img)\n",
    "    data=np.array(data)\n",
    "    label=np.array(label,dtype='int')\n",
    "    return data, label   \n",
    "\n",
    "def pre_process_test(path):\n",
    "    data=[]\n",
    "    with open(path, 'r') as csvFile:\n",
    "        reader = csv.reader(csvFile)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            img=np.array(row[0:],dtype='float')/255.0\n",
    "            img.resize(28,28)\n",
    "            data.append(img)\n",
    "    data=np.array(data)\n",
    "    return data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jU_xhOhKvwkO"
   },
   "outputs": [],
   "source": [
    "def save_file(path,y_predict):\n",
    "    dict={'ImageId':np.arange(y_predict.shape[0])+1, 'Label':y_predict}\n",
    "    df=pd.DataFrame(dict)\n",
    "    df.to_csv('sample_submission.csv',index=False,header=True )\n",
    "    return \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-beLnWyYTKBo"
   },
   "outputs": [],
   "source": [
    "data_train, label_train=pre_process('train.csv')\n",
    "data_test=pre_process_test('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0dNrxrPfVnOl"
   },
   "outputs": [],
   "source": [
    "x_train_img, x_val_img, label_train, label_val = train_test_split(data_train, label_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "QcbrQ7A7TNbr",
    "outputId": "35cd10d0-c89b-4c7c-b82e-2b558d27b861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image train num:  42000\n",
      "image test num:  28000\n",
      "label:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('image train num: ',len(data_train))\n",
    "print('image test num: ',len(data_test))\n",
    "print('label: ',label_train[100])\n",
    "plt.imshow(data_train[100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JXXh7ULxTYWd"
   },
   "outputs": [],
   "source": [
    "num_classes=10\n",
    "temp=[]\n",
    "y_train = (keras.utils.to_categorical(label_train, num_classes)).T\n",
    "y_val = (keras.utils.to_categorical(label_val, num_classes)).T\n",
    "for i in range(0,len(x_train_img)):\n",
    "    temp.append(np.ndarray.flatten(x_train_img[i]))\n",
    "x_train=np.array(temp).T\n",
    "temp.clear()\n",
    "for i in range(0,len(data_test)):\n",
    "    temp.append(np.ndarray.flatten(data_test[i]))\n",
    "x_test=np.array(temp).T\n",
    "temp.clear()\n",
    "for i in range(0,len(x_val_img)):\n",
    "    temp.append(np.ndarray.flatten(x_val_img[i]))\n",
    "x_val=np.array(temp).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100
    },
    "colab_type": "code",
    "id": "W-Z5cT2ETa8x",
    "outputId": "79c4d6d4-9e27-4f44-c8a8-f599f823f9e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (784, 37800)\n",
      "y_train: (10, 37800)\n",
      "x_val: (784, 4200)\n",
      "y_val: (10, 4200)\n",
      "x_test: (784, 28000)\n"
     ]
    }
   ],
   "source": [
    "print('x_train:',x_train.shape)\n",
    "print('y_train:',y_train.shape)\n",
    "\n",
    "print('x_val:',x_val.shape)\n",
    "print('y_val:',y_val.shape)\n",
    "\n",
    "print('x_test:',x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6NyzjksfUtAW"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):# Hàm sigmoid\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_grad(a):# Đạp hàm sigmoid\n",
    "    return a*(1-a)\n",
    "\n",
    "def relu(x):# hàm relu\n",
    "    x[x<0] = 0\n",
    "    return x\n",
    "\n",
    "def relu_grad(a):# Đạo hàm hàm relu\n",
    "    a[a>0] = 1\n",
    "    return a\n",
    "\n",
    "def softmax(x):# Hàm softmax\n",
    "    output = np.exp(x-x.max())\n",
    "    output = output/output.sum(axis=0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ulu3qJjSUwGN"
   },
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    def __init__(self,input_shape,num_node,activation='relu'):\n",
    "        self.input_shape=input_shape #(feature,num)\n",
    "        self.num_node=num_node #number node\n",
    "        self.activation=activation\n",
    "        self.w=0.01*np.random.rand(input_shape[0],self.num_node) #(pre_layer num_node,layer_numnode)\n",
    "        self.b=np.zeros((num_node,1))\n",
    "    \n",
    "    # Lan truyền tiến\n",
    "    def forward(self,pre_a):\n",
    "        z=np.dot(self.w.T,pre_a)+self.b #()\n",
    "        \n",
    "        if self.activation=='relu':\n",
    "            a=relu(z)\n",
    "            \n",
    "        if self.activation=='sigmoid':\n",
    "            a=sigmoid(z)\n",
    "            \n",
    "        if self.activation=='softmax':\n",
    "            a=softmax(z)      \n",
    "        return a\n",
    "    \n",
    "    def backward(self,pre_a, pre_theta, pre_w):\n",
    "        \n",
    "        a=self.forward(pre_a)\n",
    "        \n",
    "        if self.activation == 'sigmoid':\n",
    "            da_dz = sigmoid_grad(a)\n",
    "            \n",
    "        if self.activation == 'relu':\n",
    "            da_dz = relu_grad(a)\n",
    "        \n",
    "        theta=np.dot(pre_w,pre_theta)*da_dz\n",
    "        \n",
    "        d_w=np.dot(pre_a,theta.T)\n",
    "        \n",
    "        d_b = np.sum(theta, axis = 1, keepdims = True)\n",
    "        \n",
    "        return d_w,d_b,theta\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zRSDSwSYUyUF"
   },
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        \n",
    "    # Thêm layer vào Mô hình NN    \n",
    "    def add_layer(self,input_shape,num_node,activation):\n",
    "        self.layers.append(Layer(input_shape,num_node,activation))\n",
    "    \n",
    "    # Tính đỗ lỗi mô hình\n",
    "    def compute_loss(self,y, y_hat):\n",
    "        return -np.sum(y*np.log(y_hat))/y.shape[1]\n",
    "      \n",
    "      \n",
    "    # LAn truyền tiến trên NN\n",
    "    def forward(self,X):\n",
    "        A = [X]\n",
    "        # output của mỗi layer được append vào A\n",
    "        for layer in self.layers:\n",
    "            A.append(layer.forward(A[-1]))\n",
    "        return A\n",
    "    #Lan truyền ngược trên NN\n",
    "    \n",
    "    def backward(self,y,A):\n",
    "        # tính toán tham số của oupput layer\n",
    "        theta_L = (A[-1] - y)/y.shape[1]\n",
    "        dW_L = np.dot(A[-2],theta_L.T)\n",
    "        \n",
    "        dB_L = np.sum(theta_L, axis = 1, keepdims = True)\n",
    "        \n",
    "        dW_list =[dW_L]\n",
    "        \n",
    "        dB_list =[dB_L]\n",
    "\n",
    "        prev_theta = theta_L\n",
    "        \n",
    "        # Thực hiện lan truyền ngược\n",
    "        for i in range(0,len(self.layers)-1)[::-1]:\n",
    "            prev_a = A[i]\n",
    "            prev_w =self.layers[i + 1].w\n",
    "            dw,db,prev_theta = self.layers[i].backward(prev_a,prev_theta,prev_w)\n",
    "            dW_list.append(dw)\n",
    "            dB_list.append(db)\n",
    "        return dW_list[::-1],dB_list[::-1]\n",
    "\n",
    "    # CẬP nhật trong số\n",
    "    def update_w(self, dW_list,dB_list, learning_rate):\n",
    "        for i in range(len(self.layers)):\n",
    "            self.layers[i].w = self.layers[i].w - learning_rate * dW_list[i]\n",
    "            self.layers[i].b = self.layers[i].b - learning_rate * dB_list[i]\n",
    "            \n",
    "    \n",
    "    def random_mini_batches(self,X_data,y_data,mini_batch_size):\n",
    "        \n",
    "        X=X_data.T\n",
    "        y=y_data.T\n",
    "      \n",
    "        m = X.shape[0]\n",
    "        \n",
    "        mini_batches = []\n",
    "        permutation = list(np.random.permutation(m))\n",
    "        shuffled_X = X[permutation,:]\n",
    "        shuffled_Y = y[permutation,:]\n",
    "\n",
    "        # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "        num_complete_minibatches = math.floor(\n",
    "            m / mini_batch_size)  # number of mini batches of size mini_batch_size in your partitionning\n",
    "        for k in range(0, num_complete_minibatches):\n",
    "            mini_batch_X = shuffled_X[ k * mini_batch_size: (k + 1) * mini_batch_size,:]\n",
    "            mini_batch_Y = shuffled_Y[ k * mini_batch_size: (k + 1) * mini_batch_size,:]\n",
    "            mini_batch = (mini_batch_X.T, mini_batch_Y.T)\n",
    "            mini_batches.append(mini_batch)\n",
    "\n",
    "        # Handling the end case (last mini-batch < mini_batch_size)\n",
    "        if m % mini_batch_size != 0:\n",
    "            mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size: m,:]\n",
    "            mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size: m,:]\n",
    "            mini_batch = (mini_batch_X.T, mini_batch_Y.T)\n",
    "            mini_batches.append(mini_batch)\n",
    "\n",
    "        return mini_batches\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "    def fit(self,X,y,label_train,x_val,label_val,learning_rate=0.05,epochs=5, batch_size=32):\n",
    "        all_loss = []\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            mini_batches = self.random_mini_batches(X,y,batch_size)\n",
    "            for mini_batch_X, mini_batch_Y in mini_batches:   \n",
    "                A = self.forward(mini_batch_X)\n",
    "                y_hat = A[-1]\n",
    "                loss = self.compute_loss(mini_batch_Y, y_hat)\n",
    "                dW_list,dB_list = self.backward(mini_batch_Y, A)\n",
    "                self.update_w(dW_list,dB_list, learning_rate)              \n",
    "            \n",
    "            B=self.forward(x_val)\n",
    "            predicted_class = np.argmax(B[-1], axis=0)\n",
    "            C=self.forward(X)\n",
    "            predicted_class_train = np.argmax(C[-1], axis=0)\n",
    "            \n",
    "            print(\"Epoch %d: loss is %.5f\" % (e + 1, loss),',train acc: %.2f %%' % (100*np.mean(predicted_class_train == label_train))\n",
    "                  ,',val acc: %.2f %%' % (100*np.mean(predicted_class == label_val)))\n",
    "                \n",
    "        return all_loss\n",
    "              \n",
    "          \n",
    "      \n",
    "    def predict(self,X):\n",
    "        A=self.forward(X)\n",
    "        predicted_class = np.argmax(A[-1], axis=0)\n",
    "        #print('training accuracy: %.2f %%' % (100*np.mean(predicted_class == y)))\n",
    "        \n",
    "        return predicted_class\n",
    "      \n",
    "      \n",
    "        \n",
    "      \n",
    "      \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NeaGYFqwU1oX"
   },
   "outputs": [],
   "source": [
    "NN=Neural_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CADxbsvIU5mi"
   },
   "outputs": [],
   "source": [
    "NN.add_layer(input_shape=x_test.shape,num_node=1000,activation='relu')\n",
    "NN.add_layer(input_shape=(1000,x_test.shape[1]),num_node=10,activation='softmax')\n",
    "#NN.add_layer(input_shape=(128,x_test.shape[1]),num_node=32,activation='relu')\n",
    "#NN.add_layer(input_shape=(32,x_test.shape[1]),num_node=10,activation='softmax')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150
    },
    "colab_type": "code",
    "id": "ms0AkUX2U6NG",
    "outputId": "813d6d2f-c9f5-48ed-b102-8fbe1997dcb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss is 0.06288 ,train acc: 92.05 % ,val acc: 91.60 %\n",
      "Epoch 2: loss is 0.62089 ,train acc: 91.96 % ,val acc: 90.69 %\n",
      "Epoch 3: loss is 0.02709 ,train acc: 96.72 % ,val acc: 95.83 %\n",
      "Epoch 4: loss is 0.55114 ,train acc: 91.66 % ,val acc: 90.14 %\n",
      "Epoch 5: loss is 0.01448 ,train acc: 97.89 % ,val acc: 96.62 %\n",
      "Epoch 6: loss is 0.13216 ,train acc: 98.41 % ,val acc: 96.86 %\n",
      "Epoch 7: loss is 0.00106 ,train acc: 98.70 % ,val acc: 97.02 %\n",
      "Epoch 8: loss is 0.05576 ,train acc: 98.66 % ,val acc: 97.02 %\n",
      "Epoch 9: loss is 0.00288 ,train acc: 99.07 % ,val acc: 97.29 %\n",
      "Epoch 10: loss is 0.00444 ,train acc: 99.32 % ,val acc: 97.50 %\n",
      "Epoch 11: loss is 0.00108 ,train acc: 99.43 % ,val acc: 97.62 %\n",
      "Epoch 12: loss is 0.00561 ,train acc: 99.55 % ,val acc: 97.83 %\n",
      "Epoch 13: loss is 0.01445 ,train acc: 99.63 % ,val acc: 97.57 %\n",
      "Epoch 14: loss is 0.01134 ,train acc: 99.79 % ,val acc: 97.86 %\n",
      "Epoch 15: loss is 0.00756 ,train acc: 99.83 % ,val acc: 97.50 %\n",
      "Epoch 16: loss is 0.00086 ,train acc: 99.86 % ,val acc: 97.76 %\n",
      "Epoch 17: loss is 0.00047 ,train acc: 99.91 % ,val acc: 97.71 %\n",
      "Epoch 18: loss is 0.00500 ,train acc: 99.94 % ,val acc: 97.88 %\n",
      "Epoch 19: loss is 0.00249 ,train acc: 99.97 % ,val acc: 97.74 %\n",
      "Epoch 20: loss is 0.00056 ,train acc: 99.98 % ,val acc: 97.60 %\n",
      "Epoch 21: loss is 0.02279 ,train acc: 99.96 % ,val acc: 97.79 %\n",
      "Epoch 22: loss is 0.00665 ,train acc: 99.98 % ,val acc: 97.88 %\n",
      "Epoch 23: loss is 0.00086 ,train acc: 99.98 % ,val acc: 97.76 %\n",
      "Epoch 24: loss is 0.00241 ,train acc: 99.99 % ,val acc: 97.86 %\n",
      "Epoch 25: loss is 0.00397 ,train acc: 99.99 % ,val acc: 97.83 %\n",
      "Epoch 26: loss is 0.00319 ,train acc: 100.00 % ,val acc: 97.76 %\n",
      "Epoch 27: loss is 0.00095 ,train acc: 100.00 % ,val acc: 97.90 %\n",
      "Epoch 28: loss is 0.00042 ,train acc: 100.00 % ,val acc: 97.79 %\n",
      "Epoch 29: loss is 0.01578 ,train acc: 100.00 % ,val acc: 97.98 %\n",
      "Epoch 30: loss is 0.00008 ,train acc: 100.00 % ,val acc: 97.88 %\n",
      "Epoch 31: loss is 0.00287 ,train acc: 100.00 % ,val acc: 97.86 %\n",
      "Epoch 32: loss is 0.00672 ,train acc: 100.00 % ,val acc: 97.88 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.fit(x_train,y_train,label_train,x_val,label_val,learning_rate=0.1,epochs=32, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6sppH0uxVBdU"
   },
   "outputs": [],
   "source": [
    "kq=NN.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OpIlZtxCb-3l"
   },
   "outputs": [],
   "source": [
    "save_file('sample_submission.csv',np.array(kq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CMGTnEHRTTyl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NN_new.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
